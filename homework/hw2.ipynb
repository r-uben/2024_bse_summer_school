{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  # Description\n",
    "\n",
    "  \n",
    "  ðŸŒŸ Objective: Classification with various techniques on this dataset.\n",
    "\n",
    "  Dataset link: https://huggingface.co/datasets/dair-ai/emotion?library=datasets\n",
    " \n",
    " ðŸ“‹ Tasks:\n",
    "   1. **Baseline Implementation**: \n",
    "      - Train a tf-idf + logistic regression classifier with 5%, 10%, 25%, 50%, and 100% of the data.\n",
    "      - Plot the learning curve (f1/precision/recall) based on the volume of data.\n",
    "   2. **BERT Implementation**: \n",
    "      - Train a BERT classifier with 5%, 10%, 25%, 50%, and 100% of the data.\n",
    "      - Add its learning curve (f1/precision/recall) to the previous plot.\n",
    "   3. **BERT Model with Limited Data**: \n",
    "      - Train a setfit model using only 32 labeled examples and assess its performance.\n",
    "      - Add a horizontal line on the previous plot.\n",
    "   4. **Zero Shot Technique**: \n",
    "      - Apply a large language model in a zero-shot learning setup with an LLM such as chatGPT.\n",
    "      - If you can't apply it on all the data, a small sample should suffice.\n",
    "      - Add a horizontal line on the previous plot.\n",
    "   5. **Generate New Data from Scratch**: \n",
    "      - Use the LLM to generate a few samples for each class (10, 50, 100).\n",
    "      - Recreate the learning curve and add the performances to the previous plot.\n",
    "   6. **Bonus Question**: \n",
    "      - Examine some differences in what the models have learned.\n",
    " \n",
    " ðŸ”— Helpful Link:\n",
    " This link might be useful for interacting with the LLM: [Native JSON Output from GPT-4](https://yonom.substack.com/p/native-json-output-from-gpt-4). It explains how to ask the model to provide information in a JSON format, which will be easier to organize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Housekeeping\n",
    "\n",
    "Let's start by loading all the necessary libraries and the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "from src.utils import Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data import Data\n",
    "Data().ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Data().ds\n",
    "# Print a few samples from the training set\n",
    "print(\"Training set samples:\\n\")\n",
    "for i, sample in enumerate(data['train'].select(range(5))):\n",
    "    print(f\"Sample {i+1}:\")\n",
    "    print(f\"Text: {sample['text']}\")\n",
    "    print(f\"Label: {sample['label']}\")\n",
    "    print()\n",
    "\n",
    "# Print the unique labels\n",
    "unique_labels = set(data['train']['label'] + data['validation']['label'] + data['test']['label'])\n",
    "print(\"Unique labels:\", unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data().generate_word_clouds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data().plot_label_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Baseline Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.baseline import Baseline\n",
    "\n",
    "baseline = Baseline(\n",
    "    data = Data(),\n",
    "    seed = 100,\n",
    "    test_size = 0.20,\n",
    "    num_percentiles = 20\n",
    ")\n",
    "\n",
    "baseline.results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = go.Figure()\n",
    "fig = Utils.plot_metrics(baseline.results)\n",
    "fig.update_layout(\n",
    "    title='Learning Curve: TF-IDF + Logistic Regression',\n",
    "    xaxis_title='Percentage of Training Data',\n",
    "    yaxis_title='Score',\n",
    "    legend_title='Metric',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import BertTokenizer, TFBertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.bert import BERT\n",
    "\n",
    "bert = BERT(Data())\n",
    "bert.results.head()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = go.Figure()\n",
    "fig = Utils.plot_metrics(bert.results)\n",
    "fig.update_layout(\n",
    "    title='Learning Curve: BERT',\n",
    "    xaxis_title='Percentage of Training Data',\n",
    "    yaxis_title='Score',\n",
    "    legend_title='Metric',\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
